{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 21:55:40.878652: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-28 21:55:40.916322: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 21:55:41.996464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add Lookup List for Chemo\n",
    "- before training my models, add some extra terms to expand the lexicons\n",
    "- can't check fn here, here just compared with additional mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indexs\n",
    "breast_train_terms = [\"docetaxel\", \"cyclophosphamide\", \\\n",
    "                      \"doxorubicin\", \\\n",
    "                        'herceptin', \"perjeta\"]\n",
    "breast_train_short_terms = [\"chemo\", \"AC-T\", \"A/C\"] # \"Docetaxol\"\n",
    "\n",
    "# interferon need to add rule not add when it is a a/btest\n",
    "# melanoma_train_terms = [\"temozolomide\", \"tasisulam\", \"alfa-2b interferon\", \"vaccinia virus\", \\\n",
    "#                         \"alpha-2b interferon\", \"carboplatin\", \"Vaccinia  virus\", \"melphalan\"]\n",
    "melanoma_train_terms = [\"temozolomide\", \"tasisulam\", \"vaccinia virus\", \\\n",
    "                        \"carboplatin\", \"Vaccinia  virus\", \"melphalan\"]\n",
    "melanoma_train_short_terms = [\"chemo\"]\n",
    "\n",
    "# actually from test\n",
    "ovarian_train_terms = [\"taxol\", \"carboplatin\", \"cisplatin\", \"etoposide\"]\n",
    "ovarian_train_short_terms = [\"chemo\"]\n",
    "\n",
    "def _get_seindexs_whole_note(string, spacy_better):\n",
    "    doc = spacy_better(string)\n",
    "    seindexs_whole_note = [] \n",
    "    for i, sent in enumerate(doc.sents):\n",
    "        seindexs_whole_note.append((i, sent.start_char, sent.end_char))\n",
    "    return seindexs_whole_note\n",
    "\n",
    "def _find_nthind(tuple_list, start_ind):\n",
    "    for tup in tuple_list:\n",
    "        if tup[1] <= start_ind <= tup[2]:\n",
    "            return tup[0]\n",
    "    print(\"something wrong with this case\")\n",
    "    return None  # Return None if no match is found\n",
    "\n",
    "\n",
    "# Lookup Add Chemos in Single Note\n",
    "def _lookup_chemo(spacy_better, string, terms, short_terms, cancer, mode, patient_filename):\n",
    "    \"\"\"string: note with replacement \\n\"\"\"\n",
    "    sent_char_index_lst = _get_seindexs_whole_note(string, spacy_better) # (nth, start ind char of nth, end char ind of nth)\n",
    "    matches = []\n",
    "    if cancer == \"breast\": \n",
    "        pattern = r'\\b' + re.escape(\"A.C\") + r'\\b'\n",
    "        for match in re.finditer(pattern, string):\n",
    "            start_index = match.start()\n",
    "            end_index = match.end()\n",
    "            matched_word = string[start_index:end_index]\n",
    "            nth_sent = _find_nthind(sent_char_index_lst, start_index)\n",
    "            matches.append((nth_sent, cancer, mode, patient_filename, matched_word, start_index, end_index))    # after mapping the vaccina virus first, then look for any virus left\n",
    "    # if cancer == \"melanoma\": \n",
    "    #     pattern = r'\\b' + re.escape(\"interferon\") + r'\\b'\n",
    "    #     exclude_pattern1 = r'\\b' + re.escape(\"alfa-2b interferon\") + r'\\b'\n",
    "    #     exclude_pattern2 = r'\\b' + re.escape(\"alpha-2b interferon\") + r'\\b'\n",
    "    #     exclude_end1_lst, exclude_end2_lst = [], []\n",
    "    #     for exclude_match1 in re.finditer(exclude_pattern1, string, re.IGNORECASE):\n",
    "    #         exclude_end1_lst.append(exclude_match1.end())\n",
    "    #     for exclude_match2 in re.finditer(exclude_pattern2, string, re.IGNORECASE):\n",
    "    #         exclude_end2_lst.append(exclude_match2.end())\n",
    "    #     for match in re.finditer(pattern, string, re.IGNORECASE):\n",
    "    #         end_index = match.end()\n",
    "    #         if (end_index not in exclude_end1_lst) and (end_index not in exclude_end2_lst): \n",
    "    #             start_index = match.start()\n",
    "    #             end_index = match.end()\n",
    "    #             matched_word = string[start_index:end_index]\n",
    "    #             nth_sent = _find_nthind(sent_char_index_lst, start_index)\n",
    "    #             matches.append((nth_sent, cancer, mode, patient_filename, matched_word, start_index, end_index))        \n",
    "        pattern = r'\\b' + re.escape(\"vaccinia\") + r'\\b'\n",
    "        exclude_pattern1 = r'\\b' + re.escape(\"vaccinia virus\") + r'\\b'\n",
    "        exclude_pattern2 = r'\\b' + re.escape(\"vaccinia  virus\") + r'\\b'\n",
    "        exclude_start1_lst, exclude_start2_lst = [], []\n",
    "        for exclude_match1 in re.finditer(exclude_pattern1, string, re.IGNORECASE):\n",
    "            exclude_start1_lst.append(exclude_match1.start())\n",
    "        for exclude_match2 in re.finditer(exclude_pattern2, string, re.IGNORECASE):\n",
    "            exclude_start2_lst.append(exclude_match2.start())\n",
    "        for match in re.finditer(pattern, string, re.IGNORECASE):\n",
    "            start_index = match.start()\n",
    "            if (start_index not in exclude_start1_lst) and (start_index not in exclude_start2_lst): \n",
    "                start_index = match.start()\n",
    "                end_index = match.end()\n",
    "                matched_word = string[start_index:end_index]\n",
    "                nth_sent = _find_nthind(sent_char_index_lst, start_index)\n",
    "                matches.append((nth_sent, cancer, mode, patient_filename, matched_word, start_index, end_index))            \n",
    "    for term in terms:\n",
    "        for match in re.finditer(re.escape(term), string, re.IGNORECASE):\n",
    "            start_index = match.start()\n",
    "            end_index = match.end()\n",
    "            matched_word = string[start_index:end_index]\n",
    "            nth_sent = _find_nthind(sent_char_index_lst, start_index)\n",
    "            matches.append((nth_sent, cancer, mode, patient_filename, matched_word, start_index, end_index))\n",
    "           # string[i] = string[:start_index] + '*' * (end_index - start_index) + string[end_index:]\n",
    "    for term in short_terms:\n",
    "        pattern = r'\\b' + re.escape(term) + r'\\b'\n",
    "        for match in re.finditer(pattern, string, re.IGNORECASE):\n",
    "            start_index = match.start()\n",
    "            end_index = match.end()\n",
    "            matched_word = string[start_index:end_index]\n",
    "            nth_sent = _find_nthind(sent_char_index_lst, start_index)\n",
    "            matches.append((nth_sent, cancer, mode, patient_filename, matched_word, start_index, end_index))\n",
    "            # string[i] = string[:start_index] + '*' * (end_index - start_index) + string[end_index:]\n",
    "    return matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add Lookup List for Timex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timex_terms = [\"currently\", \"today\"]\n",
    "timex_short_terms = []\n",
    "\n",
    "# Lookup Add Chemos in Single Note\n",
    "def _lookup_timex(spacy_better, string, terms, short_terms, cancer, mode, patient_filename, dct):\n",
    "    \"\"\"string: note with replacement \\n \n",
    "    dct: dct from this note\"\"\"\n",
    "    if dct is None: \n",
    "        return []\n",
    "    sent_char_index_lst = _get_seindexs_whole_note(string, spacy_better) # (nth, start ind char of nth, end char ind of nth)\n",
    "    matches = []          \n",
    "    for term in terms:\n",
    "        for match in re.finditer(re.escape(term), string, re.IGNORECASE):\n",
    "            start_index = match.start()\n",
    "            end_index = match.end()\n",
    "            matched_word = string[start_index:end_index]\n",
    "            nth_sent = _find_nthind(sent_char_index_lst, start_index)\n",
    "            matches.append((nth_sent, cancer, mode, patient_filename, matched_word, start_index, end_index, dct))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create New TSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New Unsummarized File If Change\n",
    "def new_tsv(UNSUMMARIZED_FILE, OUT_UNSUMMARIZED_FILE, more_df_tsv):\n",
    "    unsum_df = pd.read_csv(UNSUMMARIZED_FILE, sep=\"\\t\")\n",
    "    new_df = pd.concat([unsum_df, more_df_tsv], ignore_index=True, axis=0)\n",
    "    new_df.to_csv(OUT_UNSUMMARIZED_FILE, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply to All File with Certain Cancer Type & Mode\n",
    "def _lookup_cancer_modes(PATIENT_NOTE_DIR, terms, short_terms, timex_terms, timex_short_terms, cancer, mode):\n",
    "    gold_dct_file = f\"/users/the/NER_MTB/0_{cancer}_{mode}_gold_dct.json\"\n",
    "    with open(gold_dct_file, \"r\") as infile:\n",
    "        gold_dct = json.load(infile)\n",
    "    dct_lst, pi_lst, ct_lst, cai_lst, nt_lst, tai_lst, t_lst, nn_lst, ti_lst = [], [], [], [], [], [], [], [], []\n",
    "    spacy_better = spacy.load(\"en_core_web_sm\")\n",
    "    for dir in os.listdir(PATIENT_NOTE_DIR):\n",
    "        subfolder = os.path.join(PATIENT_NOTE_DIR, dir)\n",
    "        if os.path.isdir(subfolder):\n",
    "            for filename in os.listdir(subfolder):\n",
    "                file = os.path.join(subfolder, filename)\n",
    "                with open(file, \"r\") as infile:\n",
    "                    lines = infile.readlines()\n",
    "                # note with replacement \\n\n",
    "                line = lines[9:][0]\n",
    "                if filename.split(\"_\")[0] not in gold_dct: \n",
    "                    continue\n",
    "                if \"_\".join(filename.split(\"_\")[1:]).split(\".txt\")[0] in gold_dct[filename.split(\"_\")[0]].keys(): \n",
    "                    chemo_lst = gold_dct[filename.split(\"_\")[0]][\"_\".join(filename.split(\"_\")[1:]).split(\".txt\")[0]][\"pair_wise\"][\"chemo\"][\"ment\"]\n",
    "                    time_lst = gold_dct[filename.split(\"_\")[0]][\"_\".join(filename.split(\"_\")[1:]).split(\".txt\")[0]][\"pair_wise\"][\"time\"][\"ment\"]\n",
    "\n",
    "                    dct_str = gold_dct[filename.split(\"_\")[0]][\"_\".join(filename.split(\"_\")[1:]).split(\".txt\")[0]][\"doc_create_time\"]\n",
    "                    \n",
    "                    add_timex_lst = _lookup_timex(spacy_better, line, timex_terms, timex_short_terms, cancer, mode, filename, dct_str[\"ment\"])\n",
    "                else:\n",
    "                    chemo_lst = []\n",
    "                    time_lst = []\n",
    "                    add_timex_lst = []\n",
    "                # note with replacement \\n\n",
    "                add_chemo_lst = _lookup_chemo(spacy_better, line, terms, short_terms, cancer, mode, filename)\n",
    "                \n",
    "                # check false positive\n",
    "                add_chemo_text_lst = []\n",
    "                add_timex_text_lst = []\n",
    "                for row in add_chemo_lst:\n",
    "                    add_chemo_text = row[4]\n",
    "                    add_chemo_text_lst.append(add_chemo_text)\n",
    "                for row in add_timex_lst:\n",
    "                    add_timex_text = (row[4], row[-1])\n",
    "                    add_timex_text_lst.append(add_timex_text)\n",
    "                if len(chemo_lst) > 0:\n",
    "                    # print(add_chemo_text_lst)\n",
    "                    fp = set(add_chemo_text_lst)-set(chemo_lst)\n",
    "                    if len(fp) > 0:\n",
    "                        print(cancer, mode, filename)\n",
    "                        print(f\"false postive: {fp}\")\n",
    "                        print(\"\\n\")\n",
    "                # if len(time_lst) > 0:\n",
    "                #     add_timex_text_lst = [x[0] for x in add_timex_text_lst]\n",
    "                #     fp = set(add_timex_text_lst)-set(time_lst)\n",
    "                #     if len(fp) > 0:\n",
    "                #         print(cancer, mode, filename)\n",
    "                #         print(f\"false postive: {fp}\")\n",
    "                #         print(\"\\n\")\n",
    "                    # fn = set(time_lst) - set(add_timex_text_lst)\n",
    "                    # if len(fn) > 0:\n",
    "                    #     print(cancer, mode, filename)\n",
    "                    #     print(f\"still missing: {fn}\")\n",
    "                    #     print(\"\\n\")\n",
    "\n",
    "\n",
    "                chemo_add_nthsent_lst, timex_add_nthsent_lst = [x[0] for x in add_chemo_lst], [x[0] for x in add_timex_lst]\n",
    "                if len(chemo_add_nthsent_lst) == 0 or len(timex_add_nthsent_lst) == 0:\n",
    "                    pass\n",
    "                else: \n",
    "                    # can add more once have nth for all tsv file !!!!\n",
    "                    for cind, chemo_nth in enumerate(chemo_add_nthsent_lst): \n",
    "                        for tind, timex_nth in enumerate(timex_add_nthsent_lst):\n",
    "                            if abs(int(chemo_nth)-int(timex_nth)) == 0: \n",
    "                                yr, mn, da = add_timex_lst[tind][-1][:4], add_timex_lst[tind][-1][4:6], add_timex_lst[tind][-1][6:]\n",
    "                                dct_lst.append(f\"{yr}-{mn}-{da}\")\n",
    "                                pi_lst.append(filename.split(\"_\")[0])\n",
    "                                ct_lst.append(add_chemo_lst[cind][4])\n",
    "                                cai_lst.append(\"100\"+str(cind)+f\"e@{filename.split('.txt')[0]}@system\")\n",
    "                                nt_lst.append(f\"{yr}-{mn}-{da}\")\n",
    "                                tai_lst.append(\"100\"+str(tind)+f\"e@{filename.split('.txt')[0]}@system\")\n",
    "                                nn_lst.append(filename.split(\".txt\")[0])\n",
    "                                t_lst.append(\"contains-1\")\n",
    "                                ti_lst.append(\"\")\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.DataFrame({\"DCT\":dct_lst, \"patient_id\":pi_lst, \"chemo_text\":ct_lst, \\\n",
    "                      \"chemo_annotation_id\": cai_lst, \"normed_timex\": nt_lst, \\\n",
    "                        \"timex_annotation_id\":tai_lst, \"tlink\": t_lst, \\\n",
    "                            \"note_name\":nn_lst, \"tlink_inst\":ti_lst})\n",
    "    return df \n",
    "\n",
    "# Apply to All File\n",
    "def add_lookup_main():\n",
    "    # for cancer in [\"breast\", \"ovarian\", \"melanoma\"]:\n",
    "    \n",
    "    for cancer in [\"melanoma\"]: #, \"melanoma\"\n",
    "        if cancer == \"breast\": \n",
    "            terms, short_terms = breast_train_terms, breast_train_short_terms\n",
    "        elif cancer == \"melanoma\":\n",
    "            terms, short_terms = melanoma_train_terms, melanoma_train_short_terms\n",
    "        else:\n",
    "            terms, short_terms = ovarian_train_terms, ovarian_train_short_terms\n",
    "        for mode in [\"test\"]:\n",
    "            UNSUMMARIZED_FILE = f\"/users/the/NER_MTB/timelines/chemoTimelinesBaselineSystem/output/change_n2space_task2/unsummarized_{cancer}_{mode}_task2_output.tsv\"\n",
    "            OUT_UNSUMMARIZED_DIR = f\"/users/the/NER_MTB/timelines/chemoTimelinesBaselineSystem/output/change_n2space_task2/add_lookup\"\n",
    "            os.makedirs(OUT_UNSUMMARIZED_DIR, exist_ok=True)\n",
    "            OUT_UNSUMMARIZED_FILE = os.path.join(OUT_UNSUMMARIZED_DIR, F\"unsummarized_{cancer}_{mode}_task2_output.tsv\")\n",
    "\n",
    "            PATIENT_NOTE_EXP_DIR = \"/users/the/NER_MTB/timelines/chemoTimelinesBaselineSystem/input/change_n2space_task2\"\n",
    "            PATIENT_NOTE_DIR = os.path.join(PATIENT_NOTE_EXP_DIR, f\"input_{cancer}_{mode}_task2\", f\"Patient_Notes\", f\"{cancer}\", f\"{mode}\")\n",
    "            print(f\"{cancer}, {mode}\")\n",
    "            more_df_tsv = _lookup_cancer_modes(PATIENT_NOTE_DIR, terms, short_terms, timex_terms, timex_short_terms, cancer, mode)\n",
    "            print(more_df_tsv)\n",
    "            more_df_tsv.to_csv(f\"./{cancer}_{mode}_task2_temp.csv\")\n",
    "            new_tsv(UNSUMMARIZED_FILE, OUT_UNSUMMARIZED_FILE, more_df_tsv)\n",
    "            \n",
    "\n",
    "add_lookup_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
