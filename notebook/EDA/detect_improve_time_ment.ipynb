{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE PREDICTION: extract raw time\n",
    "def find_strings_between_flags(main_string):\n",
    "    pattern = re.compile(r'<t>(.*?)</t>', re.DOTALL)\n",
    "    matches = pattern.findall(main_string)\n",
    "    return matches\n",
    "\n",
    "baseline_pred_file = \"/users/the/NER_MTB/timelines/chemoTimelinesBaselineSystem/output/all_except_breast_dev_unsummarized_output.tsv\"\n",
    "# generate raw timex for baseline pred file \n",
    "baseline_pred_df = pd.read_csv(baseline_pred_file, delimiter=\"\\t\")\n",
    "pred_unique_note_name = list(set(baseline_pred_df[\"note_name\"]))\n",
    "pred_unique_pat_id = list(set(baseline_pred_df[\"patient_id\"]))\n",
    "time_lst = baseline_pred_df[\"tlink_inst\"].apply(find_strings_between_flags)\n",
    "baseline_pred_df[\"timex\"] = [x[0] if len(x)> 0 else \"none\" for x in time_lst]\n",
    "baseline_pred_df.replace({\"none\": np.nan}, inplace=True)\n",
    "baseline_pred_df.drop(columns=[\"patient_id\", \"chemo_annotation_id\", \"timex_annotation_id\", \"tlink\"], inplace=True)\n",
    "baseline_pred_df.dropna(subset=[\"normed_timex\"], inplace=True)\n",
    "\n",
    "id = baseline_pred_df.pop(\"note_name\")\n",
    "baseline_pred_df.insert(0, \"note_name\", id)\n",
    "raw_time = baseline_pred_df.pop(\"timex\")\n",
    "baseline_pred_df.insert(3, \"timex\", raw_time)\n",
    "\n",
    "baseline_pred_df.to_csv(\"./time_ment/chemo_time_rel.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time ment accuracy\n",
    "how well of the system to extract time ment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOLD: raw time related to chemo\n",
    "# BASELINE PREDICTION: raw time related to chemo\n",
    "# ETHER PREDICTION: all raw time\n",
    "\n",
    "gold_json_file = \"/users/the/NER_MTB/0_breast_train_gold_dct.json\"\n",
    "gold_ids_file = \"/users/the/NER_MTB/chemoTimelines2024_train_dev_labeled/subtask1/All_Patient_IDs/breast_train_patient_ids.txt\"\n",
    "ether_pred_file = \"/users/the/NER_MTB/temp_0_breast_ether_dct.json\"\n",
    "\n",
    "gold_ids = []\n",
    "with open(gold_ids_file, \"r\") as infile:\n",
    "    lines = infile.readlines()\n",
    "gold_ids.extend([id.strip() for id in lines])\n",
    "sorted(gold_ids)\n",
    "with open(gold_json_file, \"r\") as infile:\n",
    "    gold_dct = json.load(infile)\n",
    "\n",
    "with open(ether_pred_file, \"r\") as infile:\n",
    "    ether_dct = json.load(infile)\n",
    "\n",
    "def _helper_baseline(baseline_pred_df, pat_id, filename):\n",
    "    print(\"BASELINE PREDICTION: \")\n",
    "    baseline_pred_chemo = baseline_pred_df[baseline_pred_df[\"note_name\"] == pat_id+\"_\"+filename][[\"DCT\",\"chemo_text\",\"normed_timex\",\"timex\"]]\n",
    "    baseline_pred_chemo.drop_duplicates(inplace=True)\n",
    "    sorted_baseline_pred_chemo = baseline_pred_chemo.sort_values(by=\"timex\").reset_index(drop=True)\n",
    "    sorted_baseline_pred_chemo.columns = [\"DCT\",\"chemo_text\",\"normed_rel_time\",\"rel_raw_time\"]\n",
    "    print(sorted_baseline_pred_chemo)\n",
    "\n",
    "def _helper_ether(ether_dct, pat_id, filename):\n",
    "    print(\"ETHER PREDICTION: \")\n",
    "    ether_time_lst, ether_normed_time_lst = ether_dct[pat_id][filename][\"pair_wise\"][\"time\"][\"ment\"], ether_dct[pat_id][filename][\"pair_wise\"][\"time\"][\"normalized_time\"]\n",
    "    ether_dctime = ether_dct[pat_id][filename][\"doc_create_time\"]\n",
    "    ether_df = pd.DataFrame({\"DCT\": ether_dctime, \"normed_all_timex\": ether_normed_time_lst, \"all_timex\":ether_time_lst})\n",
    "    ether_df = ether_df.sort_values(by=\"all_timex\").reset_index(drop=True)\n",
    "    # ether_df[\"DCT\"], ether_df[\"normed_all_timex\"] = pd.to_datetime(ether_df[\"DCT\"], errors='coerce'), pd.to_datetime(ether_df[\"normed_all_timex\"], errors='coerce')\n",
    "    print(ether_df)\n",
    "\n",
    "def _helper_gold(gold_dct, pat_id, filename):\n",
    "    print(\"GOLD:\")\n",
    "    # not always: source: chemo, target: time\n",
    "    gold_chemo_id_lst, gold_time_id_lst = gold_dct[pat_id][filename][\"chemo_time_rel\"][\"source_id\"], gold_dct[pat_id][filename][\"chemo_time_rel\"][\"target_id\"]\n",
    "    gold_tlink_lst = gold_dct[pat_id][filename][\"chemo_time_rel\"][\"rel_type\"]\n",
    "    gold_dct_str = gold_dct[pat_id][filename][\"doc_create_time\"][\"ment\"]\n",
    "    if (gold_dct_str is not None) and (gold_dct_str[-1] == \"\\n\"):\n",
    "        gold_dct_str = gold_dct_str[:-1]\n",
    "    gold_tuple= []\n",
    "    for gold_chemo_id, gold_time_id in zip(gold_chemo_id_lst, gold_time_id_lst):\n",
    "        if gold_chemo_id in gold_dct[pat_id][filename][\"pair_wise\"][\"chemo\"][\"ment_id\"]:\n",
    "            gold_chemo_ind, gold_timex_ind = gold_dct[pat_id][filename][\"pair_wise\"][\"chemo\"][\"ment_id\"].index(gold_chemo_id), gold_dct[pat_id][filename][\"pair_wise\"][\"time\"][\"ment_id\"].index(gold_time_id)\n",
    "        else:\n",
    "            gold_chemo_ind, gold_timex_ind = gold_dct[pat_id][filename][\"pair_wise\"][\"chemo\"][\"ment_id\"].index(gold_time_id), gold_dct[pat_id][filename][\"pair_wise\"][\"time\"][\"ment_id\"].index(gold_chemo_id)\n",
    "        gold_chemo, gold_timex =  gold_dct[pat_id][filename][\"pair_wise\"][\"chemo\"][\"ment\"][gold_chemo_ind], gold_dct[pat_id][filename][\"pair_wise\"][\"time\"][\"ment\"][gold_timex_ind]\n",
    "        gold_tuple.append([gold_chemo, gold_timex])\n",
    "    sorted_gold_tuple = sorted(gold_tuple, key=lambda x: x[1])\n",
    "    gold_df = pd.DataFrame(sorted_gold_tuple, columns=[\"chemo\", \"rel_raw_time\"])\n",
    "    gold_df.insert(0, \"DCT\", gold_dct_str)\n",
    "    gold_df[\"original_DCT\"] = gold_df[\"DCT\"]\n",
    "    gold_df[\"DCT\"] = pd.to_datetime(gold_df[\"DCT\"], format=\"%Y%m%d\")\n",
    "    gold_df[\"DCT\"] = gold_df[\"DCT\"].fillna(gold_df[\"original_DCT\"])\n",
    "    gold_df[\"tlink\"] = gold_tlink_lst\n",
    "    gold_df.drop(columns=[\"original_DCT\"], inplace=True)\n",
    "    if gold_df.shape[0] == 0:\n",
    "        print(\"The GOLD file didn't find any chemo related time\")\n",
    "    else:\n",
    "        print(gold_df)\n",
    "\n",
    "for pat_id in gold_ids:\n",
    "    print(f\"~~~~~~~~{pat_id}~~~~~~~~\")\n",
    "    if pat_id in gold_dct.keys():\n",
    "        baseline_patid_bool, ether_patid_bool = pat_id in pred_unique_pat_id, pat_id in ether_dct.keys()\n",
    "        if baseline_patid_bool and ether_patid_bool:\n",
    "            for filename in sorted(list(gold_dct[pat_id].keys())):\n",
    "                print(\"~~~~~~~~filename: \", pat_id+\"_\"+filename, \"~~~~~~~~\")\n",
    "\n",
    "                _helper_gold(gold_dct, pat_id, filename)\n",
    "\n",
    "                baseline_bool, ether_bool = (pat_id+\"_\"+filename) in pred_unique_note_name, filename in ether_dct[pat_id].keys() \n",
    "                if (not baseline_bool) and ether_bool:\n",
    "                    print(\"The BASELINE pred file didn't find this filename\")\n",
    "                    #_helper_ether(ether_dct, pat_id, filename)\n",
    "                elif baseline_bool and (not ether_bool):\n",
    "                    _helper_baseline(baseline_pred_df, pat_id, filename)\n",
    "                    print(\"The ETHER pred file for didn't find this filename\")\n",
    "                elif baseline_bool and ether_bool:\n",
    "                    _helper_baseline(baseline_pred_df, pat_id, filename)\n",
    "                    #_helper_ether(ether_dct, pat_id, filename)\n",
    "                else:\n",
    "                    print(\"BASELINE AND ETHER pred file didn't this filename\")\n",
    "        elif (not baseline_patid_bool) and ether_patid_bool:\n",
    "\n",
    "            for filename in sorted(list(gold_dct[pat_id].keys())):\n",
    "                print(\"~~~~~~~~filename: \", pat_id+\"_\"+filename, \"~~~~~~~~\")\n",
    "                _helper_gold(gold_dct, pat_id, filename)\n",
    "                \n",
    "                print(\"The BASELINE pred file didn't have this patient_id\")\n",
    "\n",
    "                ether_bool = filename in ether_dct[pat_id].keys() \n",
    "                if ether_bool:\n",
    "                    _helper_ether(ether_dct, pat_id, filename)\n",
    "                else:\n",
    "                    print(\"The ETHER pred file for didn't find this filename\")\n",
    "\n",
    "        elif baseline_patid_bool and (not ether_patid_bool):\n",
    "            pass # do something with baseline \n",
    "            print(\"~~~~~~~~filename: \", pat_id+\"_\"+filename, \"~~~~~~~~\")\n",
    "            _helper_gold(gold_dct, pat_id, filename)\n",
    "            \n",
    "            baseline_bool = (pat_id+\"_\"+filename) in pred_unique_note_name\n",
    "            if not baseline_bool:\n",
    "                print(\"The BASELINE pred file didn't find this filename\")\n",
    "                print(\"The ETHER pred file didn't have this patient_id\")\n",
    "            else:\n",
    "                _helper_baseline(baseline_pred_df, pat_id, filename)\n",
    "                print(\"The ETHER pred file for didn't find this filename\")\n",
    "        else: \n",
    "            print(\"The BASELINE AND ETHER pred file didn't have this patient_id\")\n",
    "    else: \n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"===================================================================\\nReport ID.....................44,a0aKz7NubdPD\\nPatient ID....................a0aKz7NubdPD\\nPatient Name..................Patient35\\nPrincipal Date................20120417\\nRecord Type...................NOTE\\n===================================================================\\n[Report de-identified (Limited dataset compliant) by De-ID v.6.24.5.1]\\n\\nInstitution of Institution\\n \\n Location, PA \\n\\n\\n\\n\\n Institution Clinical Summary\\n\\n Below represents a clinician-friendly summary of the instructions provided to the patient.\\n\\n\\n\\n\\n\\n\\n\\nPatient Name:  Patient35\\nAddress: Location\\nPatient Phone:   \\nPatient DOB:  07/19/1960\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAge:  51 Years\\n\\n\\n\\n\\n\\n\\nGender:  Female\\n\\nAdmission Date/Time:  04/17/12\\n8:00 AM\\n\\n\\n\\n MRN:   184 190\\n\\n\\n\\n FIN:  030 \\nPrinting Date/Time:  04/17/12\\n11:56 AM\\nReason For Visit:  PERS HX OF BREAST MALIGNANCY\\nDischarging Unit:  GSDS\\n\\n\\n\\n\\n\\nProviders\\n\\n\\nPCP: Person8\\n\\n\\nAttending: Person23\\n\\n\\nReferring: Person8\\n\\n\\nConsulting:  MEDICAL INFORMATION\\n\\n\\n\\n\\n Provider Discharge Diagnosis:  Allergies:  pcn [unknown]; sulfa drugs [unknown]\\n\\n\\n\\n\\n\\n\\nImmunization History:  No immunizations administered this visit\\n\\n\\n\\n\\n\\nVital Signs / Pain Score (Most recently documented values in the past 24 hours.)\\n\\n 04/17/12 11:26\\n Temp: 36 deg C\\n\\n 04/17/12 11:45\\n BP:  144/75\\n\\n 04/17/12 11:45\\n HR:  54\\n\\n 04/17/12 11:45\\n RR:  9\\n\\n 04/17/12 11:30\\n Pain Score:  0\\n\\nOxygen (Most recently documented values in the past 24 hours.)\\n\\n 04/17/12 11:45\\n SpO2:  100 %\\n\\n 04/17/12 11:26\\n O2:  6 liters/min\\n\\nMeasurements (Most recently documented values for entire visit.)\\n\\n 04/16/12 13:04\\n Height: 155.0 cm (61.0 in)\\n\\n 04/16/12 13:04\\n Weight: 55.0 kg (121.0 lbs)\\n\\n 04/16/12 13:04\\n BMI:  22.9\\n\\nVent Settings (As of: 04/17/12 11:10)\\n\\n PEEP: 2\\n\\n\\nPeak Pressure: 12\\n\\n\\n\\n\\n\\nDischarge Medications:  ANASTROZOLE (ARIMIDEX) 1 MG BY MOUTH ONCE A DAY (No Change)\\nATORVASTATIN (LIPITOR) 10 MG BY MOUTH AT BEDTIME (No Change)\\nCALCIUM CARBONATE (CALTRATE) 1,200 MG BY MOUTH 2 TIMES A DAY (No Change)\\nMULTIVITAMIN WITH MINERALS (ONE DAILY WITH MINERALS) 1 TAB BY MOUTH 2 TIMES A DAY (No Change)\\n\\n\\nMedication Information Comment:  Lab Results Not Available at Time of Discharge\\n\\n\\nISOLATION INFORMATION\\n\\n\\n Advance Directives\\n\\n Advance Directives:  No, but patient does not wish to have adv dir\\n\\n On Chart:  Advance Directives Location:  Received Advance Directives Information:  Yes\\n\\n Wishes to Discuss Advance Directives?\\nNo\\n\\n Healthcare Decision Maker(s):  ORDER INFORMATION\\nDepart Discharge Outpatient\\nDepart Activity SDS:  See Diagnosis/Procedure Specific Instructions, No driving while taking pain medication\\nDepart Diet SDS:  See Diagnosis/Procedure Specific Instructions\\nInstitution\\n\\n\\n\\n\\nInstructions Given\\n\\n Breast Reconstruction with Tissue Expanders Implant Institution\\n\\n\\n\\n Follow-up Appointments\\n\\n\\n WITHIN 1 WEEK : Person23\\n\\n\\n\\n\\n\\n\\nHOME HEALTH CARE INFORMATION\\n\\n None\\n\\n\\n\\n\\n Additional Comments:  For any questions regarding the patient's stay at our facility, please contact\\nDischarging Provider(s)\\n\\n _________________________\\n\\n *Discharge instructions electronically signed by Discharging Providers noted above.\\n\\n Discharging Nurse\\n\\n Person47\\n\\nAt:  Perform - Completed by Person48 (on 04/17/2012 11:56)\\n Sign - Completed by Person48 (on 04/17/2012 11:56)\\n VERIFY - Completed by Person48 (on 04/17/2012 11:56)\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_dct[\"patient35\"][\"report028_NOTE\"][\"raw_note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (timeset.py, line 303)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.conda/envs/linkbert/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3505\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[14], line 3\u001b[0m\n    dataset = load_dataset(\"kimihiroh/timeset\", formulation={\"timeline\"}, trust_remote_code=True)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.conda/envs/linkbert/lib/python3.8/site-packages/datasets/load.py:2523\u001b[0m in \u001b[1;35mload_dataset\u001b[0m\n    builder_instance = load_dataset_builder(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.conda/envs/linkbert/lib/python3.8/site-packages/datasets/load.py:2230\u001b[0m in \u001b[1;35mload_dataset_builder\u001b[0m\n    builder_cls = get_dataset_builder_class(dataset_module, dataset_name=dataset_name)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.conda/envs/linkbert/lib/python3.8/site-packages/datasets/load.py:245\u001b[0m in \u001b[1;35mget_dataset_builder_class\u001b[0m\n    builder_cls = import_main_class(dataset_module.module_path)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.conda/envs/linkbert/lib/python3.8/site-packages/datasets/load.py:163\u001b[0m in \u001b[1;35mimport_main_class\u001b[0m\n    module = importlib.import_module(module_path)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.conda/envs/linkbert/lib/python3.8/importlib/__init__.py:127\u001b[0m in \u001b[1;35mimport_module\u001b[0m\n    return _bootstrap._gcd_import(name[level:], package, level)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:1014\u001b[0m in \u001b[1;35m_gcd_import\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:991\u001b[0m in \u001b[1;35m_find_and_load\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:975\u001b[0m in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:671\u001b[0m in \u001b[1;35m_load_unlocked\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:839\u001b[0m in \u001b[1;35mexec_module\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:976\u001b[0m in \u001b[1;35mget_code\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:906\u001b[0m in \u001b[1;35msource_to_code\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0;36m in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/kimihiroh--timeset/0dd8e388db014ae1a6cb6525fd123eed2ccadca8952396ec897a5759db5f3f44/timeset.py:303\u001b[0;36m\u001b[0m\n\u001b[0;31m    match self.config.name:\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# <formulation> = {nli, pairwise, mrc, timeline}\n",
    "dataset = load_dataset(\"kimihiroh/timeset\", formulation={\"timeline\"}, trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
